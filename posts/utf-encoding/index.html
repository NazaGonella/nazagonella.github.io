<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>Decoding the UTFs</title>
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
    .display.math{display: block; text-align: center; margin: 0.5rem auto;}
  </style>
  <link rel="stylesheet" href="../../style.css" />
</head>
<body>
<header>
<link rel="icon" href="/assets/favicon.svg" type="image/svg">
<a class="author-name" href="/">Nazareno Gonella</a>
<nav>
<a class="title" href="/">Blog</a> <span class="separator"></span>
<a class="title" href="/about/">About</a> <span
class="separator"></span> <a class="title" href="/resume/es/">Resume</a>
</nav>
</header>
<hr />
<article>
<h2 id="decoding-the-utfs">Decoding the UTFs</h2>
<p>November 12, 2025</p>
<hr />
<p>A few days ago I started writing a JSON Parser in C. I added support
for all data types, except for Unicode escape characters: JSON accepts
values such as <code>\u0041</code> if you don‚Äôt feel like manually copy
and pasting the Unicode character. When it came time to add them to my
parser, I realized encoding Unicode characters wasn‚Äôt as easy as I
thought it was.</p>
<p>So I decided to dive deep into Unicode and its encodings, and write
about what I learned in the process. I found that UTF is something some
people don‚Äôt bother to learn about, as it‚Äôs often not necessary, but
hopefully you‚Äôll pick something up along the way.</p>
<hr />
<h3 id="unicode-is-not-just-ascii">Unicode is not just ASCII++</h3>
<p>You probably know ASCII, characters represented by numbers from 0 to
127; you may also know Unicode, same thing as ASCII but expanded, right?
There is a slight difference. ASCII and Unicode are both <em>coded
character sets</em>, they map abstract symbols to numeric values called
<em>code points</em>. The way they differ is on how they store these
code points in memory, what is called <em>encoding</em>. ASCII is both a
coded character set and an encoding format. Unicode itself is NOT an
encoding format, in fact, it has multiple encodings.</p>
<hr />
<h3 id="code-structure-and-endianness">Code Structure and
Endianness</h3>
<hr />
<h3 id="how-ascii-does-it">How ASCII does it</h3>
<p>ASCII is straightforward. These are small values; we can assign a
byte for each code point, so the character with the code point
<code>84</code> would be stored in a byte like <code>0101 0100</code>.
We can extend this idea to Unicode with a naive approach, mapping the
code point directly to bytes.</p>
<p>The problem arises from the number of characters in Unicode, over
150,000 characters that will need more than a single byte. This gets
worse when you take into account the <em>codespace</em> of Unicode, the
total set of possible codepoints Unicode defines for present and future
use, which ranges from 0 to 1,114,111 code points<a href="#fn1"
class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>, or
<code>U+0000</code> to <code>U+10FFFF</code> using Unicode notation with
the <code>U+</code> prefix.</p>
<hr />
<h3 id="utf-32-the-naive-approach">UTF-32: The Naive Approach</h3>
<p>The UTF-32 encoding solves this by assigning 4 bytes for each code
point. Code point <code>84</code> would be stored as
<code>00 00 00 54</code> in hexadecimal. A string like <code>Dog</code>
would be encoded this way:</p>
<ul>
<li>D: <code>0000 0000</code> <code>0000 0000</code>
<code>0000 0000</code> <code>0100 0100</code></li>
<li>o: <code>0000 0000</code> <code>0000 0000</code>
<code>0000 0000</code> <code>0110 1111</code></li>
<li>g: <code>0000 0000</code> <code>0000 0000</code>
<code>0000 0000</code> <code>0110 0111</code></li>
</ul>
<p>You may notice the problem UTF-32 introduces. A lot of bytes go to
waste when using the most common letters in the english alphabet. What
in ASCII takes only 3 bytes to encode (dog), becomes 12 bytes with
UTF-32. With this encoding, every character takes the same amount of
bytes, so we call UTF-32 a <em>fixed-length</em> encoding.</p>
<pre><code>int CodepointToUTF32(unsigned int codepoint, unsigned char *output) {

    if (codepoint &gt;= 0x0 &amp;&amp; codepoint &lt;= 0x10FFFF) {
        output[0] = codepoint &amp; 0xFF;
        output[1] = (codepoint &gt;&gt; 8) &amp; 0xFF;
        output[2] = (codepoint &gt;&gt; 16) &amp; 0xFF;
        output[3] = (codepoint &gt;&gt; 24) &amp; 0xFF;
        return 4;
    }

    // Invalid codepoint
    return 0;
}</code></pre>
<hr />
<h3 id="utf-16-and-surrogate-pairs">UTF-16 and Surrogate Pairs</h3>
<p>UTF-16 introduces <em>variable-width</em> encoding. Every code point
is encoded as one or two 16 bit sequences.</p>
<p>Code points less than or equal to <code>U+FFFF</code>, corresponding
to characters in the <em>Basic Multilingual Plane</em> (BMP), are
directly encoded in a 16 bit unit.</p>
<p>For code points outside the BMP (greater than <code>U+FFFF</code>),
UTF+16 uses <em>surrogate pairs</em>, each pair consist of two 16 bit
values, the first one being the <em>high surrogate</em> followed by the
<em>low surrogate</em>. TODO: explain gap</p>
<p>Surrogate pairs follow a simple formula for encoding the code
points.</p>
<ul>
<li>Subtract <code>0x10000</code> to the code point
(<strong>U</strong>), the result (<strong>U‚Äô</strong>) being a 20
bit-value in the <code>0x00000</code> - <code>0xFFFFF</code> range.</li>
<li><strong>high surrogate</strong> ‚Äì&gt; <code>1101</code>
<code>1000</code> <code>0000</code> <code>0000</code> <em>OR</em> top
ten bits of <strong>U‚Äô</strong></li>
<li><strong>low surrogate</strong> ‚Äì&gt; <code>1101</code>
<code>1100</code> <code>0000</code> <code>0000</code> <em>OR</em> bottom
ten bits of <strong>U‚Äô</strong></li>
</ul>
<p>So high surrogates have the form
<code>1101</code>-<code>10xx</code>-<code>xxxx</code>-<code>xxxx</code>
and low surrogates <code>1101</code> <code>11xx</code> <code>xxxx</code>
<code>xxxx</code>. The <code>x</code> bits are then filled with the code
point value minus <code>0x10000</code>. This substraction allows to
insert values from 0 to 2^20 - 1, an additional 1,048,576 code points.
TODO: an additional what</p>
<pre><code>int CodepointToUTF16(unsigned int codepoint, unsigned char *output) {

    if (codepoint &lt;= 0xFFFF) {
        if (codepoint &gt;= 0xD800 &amp;&amp; codepoint &lt;= 0xDFFF) return 0;
        output[0] = (unsigned char)((codepoint &gt;&gt; 8) &amp; 0xFF);
        output[1] = (unsigned char)(codepoint &amp; 0xFF);
        return 2;
    }
    else if (codepoint &lt;= 0x10FFFF) {
        unsigned int codepoint_u = codepoint - 0b10000;
        unsigned int high = (0b110110 &lt;&lt; 10) | ((codepoint_u &gt;&gt; 10) &amp; 0b1111111111);
        unsigned int low  = (0b110111 &lt;&lt; 10) | (codepoint_u &amp; 0b1111111111);

        output[0] = (high &gt;&gt; 8) &amp; 0xFF;
        output[1] = high &amp; 0xFF;
        output[2] = (low &gt;&gt; 8) &amp; 0xFF;
        output[3] = low &amp; 0xFF;
        return 4;
    }

    // Invalid codepoint
    return 0;
}</code></pre>
<hr />
<h3 id="utf-8-the-standard-encoding">UTF-8: The Standard Encoding</h3>
<p>Now let‚Äôs look into UTF-8, which also uses variable-width
encoding.</p>
<p>In UTF-8, the number of bytes it takes to store a code point
correspond to the range of the value. Code points from
<code>U+0000</code> to <code>U+007F</code> are stored in 1 byte, ranges
from <code>U+0080</code> to <code>U+07FF</code> are stored in 2 bytes,
and so on.</p>
<ul>
<li><code>U+00000</code> - <code>U+00007F</code>: 1 Byte</li>
<li><code>U+00080</code> - <code>U+0007FF</code>: 2 Bytes</li>
<li><code>U+00800</code> - <code>U+00FFFF</code>: 3 Bytes</li>
<li><code>U+01000</code> - <code>U+10FFFF</code>: 4 Bytes</li>
</ul>
<p>The Smiling Face with Sunglasses emoji üòé corresponds to the Unicode
code point <code>U+1F60E</code> which in UTF-8 uses 4 bytes. How would
you encode this?</p>
<p>If we took the same encoding as UTF-32 there would 4 bytes one next
to the other, and nothing to indicate this is a whole one character. How
do we know if this isn‚Äôt 4 characters each one taking 1 byte? Or 2
characters of 2 bytes? Let‚Äôs say we want to index the third character in
a string. How would we do that?</p>
<p>We need to to define a more complex structure when working with
variable-width encoding. An ideal encoding format will make it possible
to identify where a character starts and where it ends in a string.</p>
<p>A document with UTF-8 encoding will have every byte either be a
<em>leading byte</em>, which indicates the start of a character as well
as how many bytes follow it; or a <em>continuation byte</em>, which is
used to help indexing and to detect if the sequence is valid UTF-8.</p>
<p><code>U+1F60E</code> encoded with UTF-8 looks like this:</p>
<ul>
<li><code>(11110)000</code></li>
<li><code>(10)011111</code></li>
<li><code>(10)011000</code></li>
<li><code>(10)001110</code></li>
</ul>
<p>Inside the parentheses are the header bits. Just by looking at the
header bits we can determine if we are in a leading or continuation
byte.</p>
<p>Continuation bytes start with <code>10</code>. We look at
continuation bytes to validate UTF-8. If the number of continuation
bytes do not correspond to those indicated by the leading byte, we know
it‚Äôs invalid UTF-8.</p>
<p>Leading bytes consist of a sequence of ones followed by a zero. The
number of ones indicate the total number of bytes used by the code
point, including the leading byte. In our emoji example we see the
leading byte has header bits <code>11110</code>, so we can read the code
point as one character of 4 bytes. This rule applies to all code points
lengths except for those of 1 byte, the ASCII characters.</p>
<p>ASCII characters have a leading byte that starts with zero, followed
by the code point value. The letter <code>A</code> will be encoded in
UTF-8 the same way as one would encode it in ASCII.<a href="#fn2"
class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a></p>
<p>The rest of the bits are the data bits. These contain the code point
value in binary, padded with leading zeros.</p>
<p>We can visualize UTF-8 with this table</p>
<table>
<colgroup>
<col style="width: 26%" />
<col style="width: 25%" />
<col style="width: 11%" />
<col style="width: 11%" />
<col style="width: 11%" />
<col style="width: 11%" />
</colgroup>
<thead>
<tr>
<th>First code point</th>
<th>Last code point</th>
<th>Byte 1</th>
<th>Byte 2</th>
<th>Byte 3</th>
<th>Byte 4</th>
</tr>
</thead>
<tbody>
<tr>
<td>U+0000</td>
<td>U+007F</td>
<td>0xxxxxxx</td>
<td>-</td>
<td>-</td>
<td>-</td>
</tr>
<tr>
<td>U+0080</td>
<td>U+07FF</td>
<td>110xxxxx</td>
<td>10xxxxxx</td>
<td>-</td>
<td>-</td>
</tr>
<tr>
<td>U+0800</td>
<td>U+FFFF</td>
<td>1110xxxx</td>
<td>10xxxxxx</td>
<td>10xxxxxx</td>
<td>-</td>
</tr>
<tr>
<td>U+010000</td>
<td>U+10FFFF</td>
<td>11110xxx</td>
<td>10xxxxxx</td>
<td>10xxxxxx</td>
<td>10xxxxxx</td>
</tr>
</tbody>
</table>
<p>The table contains the bytes with the header bits set. The
<code>x</code> bits correspond to data bits holding the code point
values.</p>
<pre><code>int CodepointToUTF8(unsigned int codepoint, unsigned char *output) {
    // codepoint: U+uvwxyz
    if (codepoint &lt;= 0x7F) {
        output[0] = (unsigned char)codepoint;                            // (0)yyy zzzz
        return 1;
    } else if (codepoint &lt;= 0x7FF) {
        output[0] = (unsigned char)(0xC0 | ((codepoint &gt;&gt; 6) &amp; 0x1F));   // (110)0 0000 | 000x xxyy = (110)x xxyy
        output[1] = (unsigned char)(0x80 | (codepoint &amp; 0x3F));          // (10)00 0000 | 00yy zzzz = (10)yy zzzz
        return 2;
    } else if (codepoint &lt;= 0xFFFF) {
        output[0] = (unsigned char)(0xE0 | ((codepoint &gt;&gt; 12) &amp; 0x0F));  // (1110) 0000 | 0000 wwww = (1110) wwww
        output[1] = (unsigned char)(0x80 | ((codepoint &gt;&gt; 6) &amp; 0x3F));   // (10)00 0000 | 00xx xxyy = (10)xx xxyy
        output[2] = (unsigned char)(0x80 | (codepoint &amp; 0x3F));          // (10)00 0000 | 00yy zzzz = (10)yy zzzz
        return 3;
    } else if (codepoint &lt;= 0x10FFFF) {
        output[0] = (unsigned char)(0xF0 | ((codepoint &gt;&gt; 18) &amp; 0x07));  // (1111 0)000 | 0000 0uvv = (1111 0)uvv
        output[1] = (unsigned char)(0x80 | ((codepoint &gt;&gt; 12) &amp; 0x3F));  // (10)00 0000 | 00vv wwww = (10)vv wwww
        output[2] = (unsigned char)(0x80 | ((codepoint &gt;&gt; 6) &amp; 0x3F));   // (10)00 0000 | 00xx xxyy = (10)xx xxyy
        output[3] = (unsigned char)(0x80 | (codepoint &amp; 0x3F));          // (10)00 0000 | 00yy zzzz = (10)yy zzzz
        return 4;
    }

    // Invalid codepoint
    return 0;
}</code></pre>
<hr />
<h3 id="bonus-combining-characters">Bonus: Combining characters</h3>
<p>Not all characters have a direct visual representation (for example,
control characters like the null terminator or line breaks), and not all
characters have a single representation when encoded in Unicode. Believe
it or not, the letters <code>√©</code> and <code>eÃÅ</code> don‚Äôt share the
same code point</p>
<pre><code>c = &quot;√©&quot;
c_utf = c.encode(&quot;utf-8&quot;)
print(&quot;byte length&quot;, len(c_utf))    # output: byte length 2
print(c_utf)                        # output: b&#39;\xc3\xa9&#39;

c = &quot;eÃÅ&quot;
c_utf = c.encode(&quot;utf-8&quot;)
print(&quot;byte length&quot;, len(c_utf))    # output: byte length 3
print(c_utf)                        # output: b&#39;e\xcc\x81&#39;</code></pre>
<p>What is going on? The answer to this is <em>combining
characters</em>. These are special characters that modify preceding
characters in order to create new variations.</p>
<p>In the first example, we are using a <em>precomposed character</em>,
a character with a dedicated code point. In this case <code>√©</code> has
the code point <code>U+00E9</code>. In the next example, we are creating
a combination of two characters for <code>√©</code>, <code>U+0065</code>
+ <code>U+0301</code>, that is the letter <code>e</code> and the acute
diacritic.</p>
<p>Most letters and symbols accept combining characters, and there is no
limit to how many you can apply. This allows you to create some
monstrous-looking characters that this site‚Äôs font won‚Äôt allow me to
render properly, so I‚Äôm attaching an image</p>
<figure>
<img
src="https://upload.wikimedia.org/wikipedia/commons/4/4a/Zalgo_text_filter.png"
alt="Zalgo text!" />
<figcaption aria-hidden="true"><a
href="https://en.wikipedia.org/wiki/Zalgo_text">Zalgo
text!</a></figcaption>
</figure>
<p>Now comes a new problem: How do we know if two strings are the same?
They may look the same when printed but have totally different
encodings. Luckily, Unicode defines <em>Unicode equivalence</em> to
solve this issue.</p>
<p>Code points sequences are defined as <strong>canonically
equivalent</strong> if they represent the same abstract character while
also looking the same when displayed. In the last case <code>√©</code>
and <code>√©</code> would be an example of this type of equivalence. When
code points sequences are <strong>compatible</strong>, they might look
similar, but are used in different contexts, as they represent different
abstract characters. It is the case of <code>A</code> and
<code>ùî∏</code>. You understand the meaning of the word
<code>ùî∏mbiguous</code>, but the character <code>ùî∏</code> is primarily
used in mathematical texts.</p>
<p>Based on these equivalences the standard also defines <em>Unicode
normalization</em>, to make sure that text sequences have the same code
point equivalence. You can read more on types of normalization (and also
about UTF-16 and other characters encodings I haven‚Äôt mentioned) in this
<a href="https://mcilloni.ovh/2023/07/23/unicode-is-hard/">article</a>
by Marco Cilloni.</p>
<hr />
<h3 id="utf-8-in-code">UTF-8 in Code</h3>
<p>This C function decodes Unicode code points to UTF-8</p>
<pre><code>#include &lt;stdio.h&gt;

int CodepointToUTF8(unsigned int codepoint, unsigned char *output) {
    // codepoint: U+uvwxyz
    if (codepoint &lt;= 0x7F) {
        output[0] = (unsigned char)codepoint;                            // (0)yyy zzzz
        output[1] = &#39;\0&#39;;
        return 1;
    } else if (codepoint &lt;= 0x7FF) {
        output[0] = (unsigned char)(0xC0 | ((codepoint &gt;&gt; 6) &amp; 0x1F));   // (110)0 0000 | 000x xxyy = (110)x xxyy
        output[1] = (unsigned char)(0x80 | (codepoint &amp; 0x3F));          // (10)00 0000 | 00yy zzzz = (10)yy zzzz
        output[2] = &#39;\0&#39;;
        return 2;
    } else if (codepoint &lt;= 0xFFFF) {
        output[0] = (unsigned char)(0xE0 | ((codepoint &gt;&gt; 12) &amp; 0x0F));  // (1110) 0000 | 0000 wwww = (1110) wwww
        output[1] = (unsigned char)(0x80 | ((codepoint &gt;&gt; 6) &amp; 0x3F));   // (10)00 0000 | 00xx xxyy = (10)xx xxyy
        output[2] = (unsigned char)(0x80 | (codepoint &amp; 0x3F));          // (10)00 0000 | 00yy zzzz = (10)yy zzzz
        output[3] = &#39;\0&#39;;
        return 3;
    } else if (codepoint &lt;= 0x10FFFF) {
        output[0] = (unsigned char)(0xF0 | ((codepoint &gt;&gt; 18) &amp; 0x07));  // (1111 0)000 | 0000 0uvv = (1111 0)uvv
        output[1] = (unsigned char)(0x80 | ((codepoint &gt;&gt; 12) &amp; 0x3F));  // (10)00 0000 | 00vv wwww = (10)vv wwww
        output[2] = (unsigned char)(0x80 | ((codepoint &gt;&gt; 6) &amp; 0x3F));   // (10)00 0000 | 00xx xxyy = (10)xx xxyy
        output[3] = (unsigned char)(0x80 | (codepoint &amp; 0x3F));          // (10)00 0000 | 00yy zzzz = (10)yy zzzz
        output[4] = &#39;\0&#39;;
        return 4;
    }

    // Invalid codepoint
    return 0;
}

int main(void) {
    unsigned char utf[5]; // The functions assigns 4 bytes max, including null terminator
    CodepointToUTF8(0x1F60E, utf);

    printf(&quot;%s\n&quot;, utf);    //  OUTPUT: üòé

    return 0;
}</code></pre>
<p>If we encode two code points in a sequence, first a base character
and then a combining character, the sequence renders as a single
displayed character</p>
<pre><code>int main(void) {
    unsigned char utf[10];
    unsigned char* p = utf;

    p += CodepointToUTF8(0x0065, utf);
    CodepointToUTF8(0x0301, p);

    printf(&quot;%s\n&quot;, utf);    // OUTPUT: √©

    return 0;
}</code></pre>
<p>Hopefully you‚Äôll now be able to make sense of a UTF-8 byte sequence
the next time you stumble upon one.</p>
</article>
<section id="footnotes" class="footnotes footnotes-end-of-document"
role="doc-endnotes">
<hr />
<ol>
<li id="fn1"><p>This doesn‚Äôt mean all code points are assigned, some
space is reserved for future use.<a href="#fnref1" class="footnote-back"
role="doc-backlink">‚Ü©Ô∏é</a></p></li>
<li id="fn2"><p>One of the major benefits of using UTF-8 is backwards
compatibility with ASCII.<a href="#fnref2" class="footnote-back"
role="doc-backlink">‚Ü©Ô∏é</a></p></li>
</ol>
</section>
</body>
</html>
