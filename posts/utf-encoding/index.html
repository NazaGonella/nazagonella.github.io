<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>Decoding the UTFs</title>
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
    .display.math{display: block; text-align: center; margin: 0.5rem auto;}
  </style>
  <link rel="stylesheet" href="../../style.css" />
</head>
<body>
<header>
<link rel="icon" href="/assets/favicon.svg" type="image/svg">
<a class="author-name" href="/">Nazareno Gonella</a>
<nav>
<a class="title" href="/">Blog</a> <span class="separator"></span>
<a class="title" href="/about/">About</a> <span
class="separator"></span> <a class="title" href="/resume/es/">Resume</a>
</nav>
</header>
<hr />
<article>
<h2 id="decoding-the-utfs">Decoding the UTFs</h2>
<p>November 12, 2025</p>
<hr />
<p>A few days ago I started writing a JSON Parser in C. I added support
for all data types, except for Unicode escape characters: JSON accepts
values such as <code>\u0041</code> if you don‚Äôt feel like manually copy
and pasting the Unicode character. When it came time to add them to my
parser, I realized encoding Unicode characters wasn‚Äôt as simple as I
thought it was.</p>
<p>So I decided to dive deep into Unicode and its encodings, and write
about what I learned in the process. I found that UTF is a topic some
people don‚Äôt bother to learn about, as it‚Äôs often not necessary, but
hopefully you‚Äôll pick something up along the way.</p>
<hr />
<h3 id="code-structure-and-endianness">Code Structure and
Endianness</h3>
<p>For each UTF encoding there will be a function
<code>CodepointToX</code> written in C that takes a code point and
transforms it to its proper encoding, returning the size of the encoding
in bytes.</p>
<p>I‚Äôm using a <em>big-endian</em> layout for writing sequential bytes:
the most significant byte comes first. This also includes a big-endian
implementation for the <code>CodepointToX</code> functions in <a
href="#utf-16-and-surrogate-pairs">UTF-16</a> and <a
href="#utf-32-the-naive-approach">UTF-32</a>. You can find little-endian
implementations in the <a href="github.com">repository</a>.</p>
<p>The <a href="#bonus-combining-characters">bonus</a> section contains
code written in Python.</p>
<hr />
<h3 id="unicode-is-not-just-ascii">Unicode is not just ASCII++</h3>
<p>You probably know ASCII, characters represented by numbers from 0 to
127; you may also know Unicode, same thing as ASCII but expanded, right?
There is a slight difference. ASCII and Unicode are both <em>coded
character sets</em>, they map abstract symbols to numeric values called
<em>code points</em>. The way they differ is on how they store these
code points in memory, what is called <em>encoding</em>. ASCII is both a
coded character set and an encoding format. Unicode itself is NOT an
encoding format, in fact, it has multiple encodings.</p>
<hr />
<h3 id="how-ascii-does-it">How ASCII does it</h3>
<p>ASCII is straightforward. These are small values; we can assign a
byte for each code point, so the character with the code point
<code>84</code> would be stored in a byte like <code>0101 0100</code>.
We can extend this idea to Unicode with a naive approach, mapping the
code point directly to bytes.</p>
<p>The problem arises from the number of characters in Unicode, over
150,000 characters that will need more than a single byte. This gets
worse when you take into account the <em>codespace</em> of Unicode, the
total set of possible codepoints Unicode defines for present and future
use, which ranges from 0 to 1,114,111 code points<a href="#fn1"
class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>, or
<code>U+0000</code> to <code>U+10FFFF</code> using Unicode notation with
the <code>U+</code> prefix.</p>
<hr />
<h3 id="utf-32-the-naive-approach">UTF-32: The Naive Approach</h3>
<p>The UTF-32 encoding solves this by assigning 4 bytes for each code
point. Code point <code>84</code> would be stored as
<code>00 00 00 54</code> in hexadecimal. A string like <code>Dog</code>
would be encoded this way:</p>
<ul>
<li>D: <code>0000 0000</code> <code>0000 0000</code>
<code>0000 0000</code> <code>0100 0100</code></li>
<li>o: <code>0000 0000</code> <code>0000 0000</code>
<code>0000 0000</code> <code>0110 1111</code></li>
<li>g: <code>0000 0000</code> <code>0000 0000</code>
<code>0000 0000</code> <code>0110 0111</code></li>
</ul>
<p>You may notice the problem UTF-32 introduces. A lot of bytes go to
waste when using the most common letters in the english alphabet. What
in ASCII takes only 3 bytes to encode (dog), becomes 12 bytes with
UTF-32. With this encoding, every character takes the same amount of
bytes, so we call UTF-32 a <em>fixed-length</em> encoding.</p>
<p>Another thing to notice is the order of the bytes, in this case we
are using big-endian. This version of UTF-32 is called
<strong>UTF-32-BE</strong>. The little-endian version is called
<strong>UTF-32-LE</strong>.</p>
<pre><code>int CodepointToUTF32BE(unsigned int codepoint, unsigned char *output) {

    if (codepoint &gt;= 0x0 &amp;&amp; codepoint &lt;= 0x10FFFF) {
        output[0] = (codepoint &gt;&gt; 24) &amp; 0xFF;
        output[1] = (codepoint &gt;&gt; 16) &amp; 0xFF;
        output[2] = (codepoint &gt;&gt; 8) &amp; 0xFF;
        output[3] = codepoint &amp; 0xFF;
        return 4;
    }

    // Invalid codepoint
    return 0;
}</code></pre>
<hr />
<h3 id="utf-16-and-surrogate-pairs">UTF-16 and Surrogate Pairs</h3>
<p>UTF-16 introduces <em>variable-width</em> encoding. Every code point
is encoded as one or two 16 bit values, called <em>code units</em>.</p>
<p>Code points less than or equal to <code>U+FFFF</code>, outside the
range <code>0xD800-0xDFFF</code> (you‚Äôll see why in a bit), correspond
to characters in the <em>Basic Multilingual Plane</em> (BMP) and are
directly encoded in a single 16 bit code unit.</p>
<p>For code points outside the BMP (greater than <code>U+FFFF</code>),
UTF-16 uses <em>surrogate pairs</em>: each pair consists of two 16 bit
code units, the first one being the <em>high surrogate</em> followed by
the <em>low surrogate</em>.</p>
<p>Surrogate pairs follow a simple formula for encoding code points.</p>
<ol type="1">
<li>Subtract <code>0x10000</code> from the code point. The result is a
20-bit number in the range <code>0x00000-0xFFFFF</code>.</li>
<li>The top 10 bits form the high surrogate: <code>1101</code>
<code>1000</code> <code>0000</code> <code>0000</code> <em>OR top ten
bits</em>.</li>
<li>The bottom 10 bits form the low surrogate: <code>1101</code>
<code>1100</code> <code>0000</code> <code>0000</code> <em>OR bottom ten
bits</em>.</li>
</ol>
<p>So high surrogates have the form <code>1101</code> <code>10xx</code>
<code>xxxx</code> <code>xxxx</code> and low surrogates <code>1101</code>
<code>11xx</code> <code>xxxx</code> <code>xxxx</code>. The
<code>x</code> bits are then filled with the code point value minus
<code>0x10000</code>. This substraction allows to insert values from 0
to 2^20 - 1, an additional 1,048,576 code points beyond the 65,536 code
points of the BMP.</p>
<p>The high surrogate range is <code>0xD800-0xDBFF</code>. The low
surrogate range is <code>0xDC00-0xDFFF</code>. The full surrogate block
<code>0xD800-0xDFFF</code> is reserved exclusively in Unicode for
surrogate code points. This means that no matter the UTF form, no
character can have a code point in this range.</p>
<p>Like UTF-32, the order of the bytes determine the version of UTF-16,
in this case we are describing <strong>UTF-16BE</strong> since it‚Äôs
big-endian. For little-endian it would be <strong>UTF-16LE</strong>.</p>
<pre><code>int CodepointToUTF16BE(unsigned int codepoint, unsigned char *output) {

    if (codepoint &lt;= 0xFFFF) {
        if (codepoint &gt;= 0xD800 &amp;&amp; codepoint &lt;= 0xDFFF) return 0; // values reserved for surrogate code points
        output[0] = (unsigned char)((codepoint &gt;&gt; 8) &amp; 0xFF);
        output[1] = (unsigned char)(codepoint &amp; 0xFF);
        return 2;
    }
    else if (codepoint &lt;= 0x10FFFF) {
        unsigned int codepoint_u = codepoint - 0b10000;
        unsigned int high = (0b110110 &lt;&lt; 10) | ((codepoint_u &gt;&gt; 10) &amp; 0b1111111111);
        unsigned int low  = (0b110111 &lt;&lt; 10) | (codepoint_u &amp; 0b1111111111);

        output[0] = (high &gt;&gt; 8) &amp; 0xFF;
        output[1] = high &amp; 0xFF;
        output[2] = (low &gt;&gt; 8) &amp; 0xFF;
        output[3] = low &amp; 0xFF;
        return 4;
    }

    // Invalid codepoint
    return 0;
}</code></pre>
<hr />
<h3 id="utf-8-the-standard-encoding">UTF-8: The Standard Encoding</h3>
<p>Now let‚Äôs look into UTF-8, which also uses variable-width
encoding.</p>
<p>In UTF-8, the number of bytes it takes to store a code point
correspond to the range of the value. Code points from
<code>U+0000</code> to <code>U+007F</code> are stored in 1 byte, ranges
from <code>U+0080</code> to <code>U+07FF</code> are stored in 2 bytes,
and so on.</p>
<ul>
<li><code>U+00000</code> - <code>U+00007F</code>: 1 Byte</li>
<li><code>U+00080</code> - <code>U+0007FF</code>: 2 Bytes</li>
<li><code>U+00800</code> - <code>U+00FFFF</code>: 3 Bytes</li>
<li><code>U+01000</code> - <code>U+10FFFF</code>: 4 Bytes</li>
</ul>
<p>The Smiling Face with Sunglasses emoji üòé corresponds to the Unicode
code point <code>U+1F60E</code> which in UTF-8 uses 4 bytes. How would
you encode this?</p>
<p>If we took the same plain encoding approach as UTF-32 there would 4
bytes one next to the other, but nothing to indicate this is a whole one
character. How do we know if this isn‚Äôt 4 characters each one taking 1
byte? Or 2 characters of 2 bytes? Let‚Äôs say we want to index the third
character in a string. How would we do that?</p>
<p>We need to define a more complex structure when working with
variable-width encoding. An ideal encoding format will make it possible
to identify where a character starts and where it ends in a string.</p>
<p>A document with UTF-8 encoding will have every byte either be a
<em>leading byte</em>, which indicates the start of a character as well
as how many bytes follow it; or a <em>continuation byte</em>, which is
used to help indexing and to detect if the sequence is valid UTF-8.</p>
<p><code>U+1F60E</code> encoded with UTF-8 looks like this:</p>
<ul>
<li><code>(11110)000</code></li>
<li><code>(10)011111</code></li>
<li><code>(10)011000</code></li>
<li><code>(10)001110</code></li>
</ul>
<p>Inside the parentheses are the header bits. Just by looking at the
header bits we can determine if we are in a leading or continuation
byte.</p>
<p>Continuation bytes start with <code>10</code>. We look at
continuation bytes to validate UTF-8. If the number of continuation
bytes do not correspond to those indicated by the leading byte, we know
it‚Äôs invalid UTF-8.</p>
<p>Leading bytes consist of a sequence of ones followed by a zero. The
number of ones indicate the total number of bytes used by the code
point, including the leading byte. In our emoji example we see the
leading byte has header bits <code>11110</code>, so we can read the code
point as one character of 4 bytes. This rule applies to all code points
lengths except for those of 1 byte, the ASCII characters.</p>
<p>ASCII characters have a leading byte that starts with zero, followed
by the code point value. The letter <code>A</code> will be encoded in
UTF-8 the same way as one would encode it in ASCII.<a href="#fn2"
class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a></p>
<p>The rest of the bits are the data bits. These contain the code point
value in binary, padded with leading zeros.</p>
<table>
<colgroup>
<col style="width: 26%" />
<col style="width: 25%" />
<col style="width: 11%" />
<col style="width: 11%" />
<col style="width: 11%" />
<col style="width: 11%" />
</colgroup>
<thead>
<tr>
<th>First code point</th>
<th>Last code point</th>
<th>Byte 1</th>
<th>Byte 2</th>
<th>Byte 3</th>
<th>Byte 4</th>
</tr>
</thead>
<tbody>
<tr>
<td>U+0000</td>
<td>U+007F</td>
<td>0xxxxxxx</td>
<td>-</td>
<td>-</td>
<td>-</td>
</tr>
<tr>
<td>U+0080</td>
<td>U+07FF</td>
<td>110xxxxx</td>
<td>10xxxxxx</td>
<td>-</td>
<td>-</td>
</tr>
<tr>
<td>U+0800</td>
<td>U+FFFF</td>
<td>1110xxxx</td>
<td>10xxxxxx</td>
<td>10xxxxxx</td>
<td>-</td>
</tr>
<tr>
<td>U+010000</td>
<td>U+10FFFF</td>
<td>11110xxx</td>
<td>10xxxxxx</td>
<td>10xxxxxx</td>
<td>10xxxxxx</td>
</tr>
</tbody>
</table>
<p>The table contains the bytes with the header bits set. The
<code>x</code> bits correspond to the data bits holding code point
values.</p>
<pre><code>int CodepointToUTF8(unsigned int codepoint, unsigned char *output) {

    if (codepoint &lt;= 0x7F) {
        output[0] = (unsigned char)codepoint;
        return 1;
    } else if (codepoint &lt;= 0x7FF) {
        output[0] = (unsigned char)(0b11000000 | ((codepoint &gt;&gt; 6) &amp; 0x1F));    // (110)0 0000 | 000x xxxx
        output[1] = (unsigned char)(0b10000000 | (codepoint &amp; 0x3F));           // (10)00 0000 | 00xx xxxx
        return 2;
    } else if (codepoint &lt;= 0xFFFF) {
        output[0] = (unsigned char)(0b11100000 | ((codepoint &gt;&gt; 12) &amp; 0x0F));   // (1110) 0000 | 0000 xxxx
        output[1] = (unsigned char)(0b10000000 | ((codepoint &gt;&gt; 6) &amp; 0x3F));    // (10)00 0000 | 00xx xxxx
        output[2] = (unsigned char)(0b10000000 | (codepoint &amp; 0x3F));           // (10)00 0000 | 00xx xxxx
        return 3;
    } else if (codepoint &lt;= 0x10FFFF) {
        output[0] = (unsigned char)(0b11110000 | ((codepoint &gt;&gt; 18) &amp; 0x07));   // (1111 0)000 | 0000 0xxx
        output[1] = (unsigned char)(0b10000000 | ((codepoint &gt;&gt; 12) &amp; 0x3F));   // (10)00 0000 | 00xx xxxx
        output[2] = (unsigned char)(0b10000000 | ((codepoint &gt;&gt; 6) &amp; 0x3F));    // (10)00 0000 | 00xx xxxx
        output[3] = (unsigned char)(0b10000000 | (codepoint &amp; 0x3F));           // (10)00 0000 | 00xx xxxx
        return 4;
    }

    // Invalid codepoint
    return 0;
}</code></pre>
<hr />
<h3 id="encoding-code-points">Encoding Code Points</h3>
<p>I will be using this wrapper to quickly print different code
points.</p>
<pre><code>void PrintCodepointChar(int codepoint) {
    unsigned char encodedChar[5];   // a Unicode character doesn&#39;t take more than 4 bytes, the 5th byte is for the null terminator

    size_t len = CodepointToUTF8(codepoint, encodedChar);

    encodedChar[len] = &#39;\0&#39;;
    printf(&quot;%s\n&quot;, encodedChar);
}</code></pre>
<p>If we run the code in a terminal with UTF-8 encoding we get the
following when printing.</p>
<pre><code>    PrintCodepointChar(0x0040);     // OUTPUT: @
    PrintCodepointChar(0xE9);       // OUTPUT: √©
    PrintCodepointChar(0x03BB);     // OUTPUT: Œª
    PrintCodepointChar(0x266A);     // OUTPUT: ‚ô™
    PrintCodepointChar(0x1F60E);    // OUTPUT: üòé
    PrintCodepointChar(0x1F40C);    // OUTPUT: üêå
    PrintCodepointChar(0x1F697);    // OUTPUT: üöó
    PrintCodepointChar(0x1F43B);    // OUTPUT: üêª</code></pre>
<p>Let‚Äôs change the wrapper function a little to showcase something cool
about Unicode.</p>
<pre><code>void PrintCodepointCombiningChar(int codepointBase, int codepointComb) {
    unsigned char encodedChars[9];

    unsigned char* p = encodedChars;
    p += CodepointToUTF8(codepointBase, encodedChars);
    p += CodepointToUTF8(codepointComb, p);

    *p = &#39;\0&#39;;
    printf(&quot;%s\n&quot;, encodedChars);
}</code></pre>
<p>In this function we define <code>encodedChars</code> as a string
containing the encoded code point <code>codepointBase</code> followed by
the encoded code point <code>codepointComb</code>.</p>
<p>If we use this function with regular characters we get</p>
<pre><code>PrintCodepointCombiningChar(0x1F47D, 0x1F916);  // OUTPUT: üëΩü§ñ
PrintCodepointCombiningChar(0x1F355, 0x1F62D);  // OUTPUT: üçïüò≠</code></pre>
<p>That was to be expected, let‚Äôs try with some other characters</p>
<pre><code>PrintCodepointChar(0x0065);                     // OUTPUT: e
PrintCodepointChar(0xE9);                       // OUTPUT: √©
PrintCodepointCombiningChar(0x0065, 0x0301);    // OUTPUT: eÃÅ</code></pre>
<p>What exactly happened in the last line? Why was the string composed
of the characters with code points <code>0x0065</code> and
<code>0x0301</code> printed as a single character?</p>
<hr />
<h3 id="bonus-combining-characters">Bonus! Combining characters</h3>
<p>Not all characters have a direct visual representation (for example,
control characters like the null terminator or line breaks), and not all
characters have a single code point when encoded in Unicode. Believe it
or not, the letters <code>√©</code> and <code>eÃÅ</code> don‚Äôt share the
same code point</p>
<pre><code>c = &quot;√©&quot;
c_utf = c.encode(&quot;utf-8&quot;)
print(&quot;byte length&quot;, len(c_utf))    # output: byte length 2
print(c_utf)                        # output: b&#39;\xc3\xa9&#39;

c = &quot;eÃÅ&quot;
c_utf = c.encode(&quot;utf-8&quot;)
print(&quot;byte length&quot;, len(c_utf))    # output: byte length 3
print(c_utf)                        # output: b&#39;e\xcc\x81&#39;</code></pre>
<p>What is going on? The answer to this is <em>combining
characters</em>. These are special characters that modify preceding
characters in order to create new variations.</p>
<p>In the first example, we are using a <em>precomposed character</em>,
a character with a dedicated code point. In this case <code>√©</code> has
the code point <code>U+00E9</code>. In the next example, we are creating
a combination of two characters for <code>√©</code>, <code>U+0065</code>
+ <code>U+0301</code>, that is the letter <code>e</code> and the acute
diacritic.</p>
<p>Most letters and symbols accept combining characters, and there is no
limit to how many you can apply. This allows you to create some
monstrous-looking characters that this site‚Äôs font won‚Äôt allow me to
render properly, so I‚Äôm attaching an image</p>
<figure>
<img
src="https://upload.wikimedia.org/wikipedia/commons/4/4a/Zalgo_text_filter.png"
alt="Zalgo text!" />
<figcaption aria-hidden="true"><a
href="https://en.wikipedia.org/wiki/Zalgo_text">Zalgo
text!</a></figcaption>
</figure>
<p>Now comes a new problem: how do we know if two strings are the same?
They may look the same when printed but have totally different
encodings. Luckily, Unicode defines <em>Unicode equivalence</em> to
solve this issue.</p>
<p>Code points sequences are defined as <strong>canonically
equivalent</strong> if they represent the same abstract character while
also looking the same when displayed. In the last case <code>√©</code>
and <code>√©</code> would be an example of this type of equivalence. When
code points sequences are <strong>compatible</strong>, they might look
similar, but are used in different contexts, as they represent different
abstract characters. It is the case of <code>A</code> and
<code>ùî∏</code>. You understand the meaning of the word
<code>ùî∏mbiguous</code>, but the character <code>ùî∏</code> is primarily
used in mathematical texts.</p>
<p>Based on these equivalences the standard also defines <em>Unicode
normalization</em>, to make sure that text sequences have the same code
point equivalence. You can read more on types of normalization in this
<a href="https://mcilloni.ovh/2023/07/23/unicode-is-hard/">article</a>
by Marco Cilloni.</p>
</article>
<section id="footnotes" class="footnotes footnotes-end-of-document"
role="doc-endnotes">
<hr />
<ol>
<li id="fn1"><p>This doesn‚Äôt mean all code points are assigned.<a
href="#fnref1" class="footnote-back" role="doc-backlink">‚Ü©Ô∏é</a></p></li>
<li id="fn2"><p>One of the major benefits of using UTF-8 is backwards
compatibility with ASCII.<a href="#fnref2" class="footnote-back"
role="doc-backlink">‚Ü©Ô∏é</a></p></li>
</ol>
</section>
</body>
</html>
